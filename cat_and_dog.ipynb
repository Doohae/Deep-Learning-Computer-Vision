{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"assignment6.ipynb","provenance":[],"authorship_tag":"ABX9TyOSoraybvuUORFeHvUVqrkm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"yY1RTrzCk4Zs"},"source":["import torchvision\n","import torch.nn as nn\n","import torch\n","import torch.nn.functional as F\n","from torchvision import models,datasets\n","# from torchvision import transforms as T\n","from torch.utils import data\n","from torchvision.models import vgg19\n","import matplotlib.pyplot as plt\n","from PIL import Image\n","import numpy as np\n","from torch import optim\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","import cv2, glob, numpy as np, pandas as pd\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","from glob import glob\n","!pip install torchsummary"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"B_-ZS0rSlElI"},"source":["!pip install -q kaggle"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ls-dL9IElM5P"},"source":["from google.colab import files\n","\n","files.upload()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pDGiGhq7lPds"},"source":["!mkdir -p ~/.kaggle\n","!cp kaggle.json ~/.kaggle/\n","!ls ~/.kaggle\n","!chmod 600 /root/.kaggle/kaggle.json"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9KyhkKKklRvV"},"source":["!kaggle datasets download -d tongpython/cat-and-dog"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CkzbDHwVlUu_"},"source":["!ls"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"B2PYc5EElWVV"},"source":["!unzip cat-and-dog.zip"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6RZslTc0lYgT"},"source":["train_data_dir = '/content/training_set/training_set'\n","test_data_dir = '/content/test_set/test_set'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SgRP44he0SF1"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FSnwHNiUn4DN"},"source":["from torchvision import transfroms as T\n","\n","trn_tfms = T.Compose([\n","    T.ToPILImage(),\n","    T.Resize((224, 224)),\n","    T.ColorJitter(brightness=(0.95,1.05), \n","                  contrast=(0.95,1.05), \n","                  saturation=(0.95,1.05), \n","                  hue=0.05),\n","    T.RandomAffine(5, translate=(0.01,0.1)),\n","    T.ToTensor(),\n","    T.Normalize(mean=[0.5, 0.5, 0.5], \n","                std=[0.25, 0.25, 0.25]),\n","])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8ZTquEt0n77r"},"source":["val_tfms = T.Compose([\n","    T.ToPILImage(),\n","    T.Resize((224, 224)),\n","    T.ToTensor(),\n","    T.Normalize(mean=[0.5, 0.5, 0.5], \n","                std=[0.25, 0.25, 0.25]),\n","])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"agFhUQ8Vyd4q"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KJfDIRG0lbgN"},"source":["from torch.utils.data import DataLoader, Dataset\n","class cats_dogs(Dataset):\n","  def __init__(self, folder, transform=None):\n","    cats = glob(folder+'/cats/*.jpg')\n","    dogs = glob(folder+'/dogs/*.jpg')\n","    self.fpaths = cats + dogs\n","    from random import shuffle, seed; seed(10); shuffle(self.fpaths)\n","    self.targets = [fpath.split('/')[-1].startswith('dog') for fpath in self.fpaths] # dog=1 & cat=0\n","    self.transfrom = transform\n","    logger.info(len(self))\n","  def __len__(self): \n","    return len(self.fpaths)\n","  def __getitem__(self, ix):\n","    f = self.fpaths[ix]\n","    target = self.targets[ix]\n","    im = (cv2.imread(f)[:,:,::-1])\n","    im = cv2.resize(im, (224,224))\n","    img = torch.tensor(im/255).permute(2,0,1).to(device).float()\n","    clss = torch.tensor([target]).float().to(device)\n","    return img, clss\n","  def choose(self):\n","    return self[randint(len(self))]\n","  def collate_fn(self, batch):\n","    _imgs, classes = list(zip(*batch))\n","    if self.transform:\n","      imgs = [self.transform(img)[None] for img in _imgs]\n","    classes = [torch.tensor([id2int[clss]]) for clss in classes]\n","    imgs, classes = [torch.cat(i).to(device) for i in [imgs, classes]]\n","    return imgs, classes, _imgs"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wdf826fgldyB"},"source":["data = cats_dogs(train_data_dir)\n","im, label = data[200]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tkRLjI5vlfxt"},"source":["len(data)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TNpfIYCZlhOd"},"source":["plt.imshow(im.permute(1,2,0).cpu())\n","print(label)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7aqKfkVilkHs"},"source":["def conv_layer(ni,no,kernel_size,stride=1):\n","    return nn.Sequential(\n","    nn.Conv2d(ni, no, kernel_size, stride),\n","    nn.ReLU(),\n","    nn.BatchNorm2d(no),\n","    nn.MaxPool2d(2)\n","    )\n","\n","class CatnDogClassifier(nn.Module):\n","  def get_model():\n","    super().__init__()\n","    self.model = nn.Sequential(\n","    conv_layer(3, 64, 3),\n","    conv_layer(64, 512, 3),\n","    conv_layer(512, 512, 3),\n","    conv_layer(512, 512, 3),\n","    conv_layer(512, 512, 3),\n","    conv_layer(512, 512, 3),\n","    nn.Flatten(),\n","    nn.Linear(512, 1),\n","    nn.Sigmoid(),\n","    ).to(device)\n","    self.loss_fn = nn.BCELoss()\n","    optimizer = torch.optim.Adam(model.parameters(), lr= 1e-3)\n","    return model, loss_fn, optimizer"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OUoq6GPk1zs6"},"source":["class VGG(nn.Module):\n","  def __init__(self):\n","    super(VGG, self).__init__()\n","    self.vgg = vgg19(pretrained=True)\n","    self.features_conv = self.vgg.features[:36]\n","    self.max_pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dialation=1, ceil_mode=False)\n","    self.classifier = self.vgg.classifier\n","    self.gradients = None\n","\n","  def activation_hook(self, grad):\n","    self.gradients = grad\n","\n","  def forward(self, x):\n","    x = self.features_conv(x)\n","    h = x.register_hook(self.activations_hook)\n","    x = self.max_pool(x)\n","    x = x.view((1, -1))\n","    x = self.classifier(x)\n","    return x\n","\n","  def get_activations_gradient(self):\n","    return self.gradients\n","\n","  def get_activations(self, x):\n","    return self.features_conv(x)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5ECFDdjS16XP"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nTvVzPdA1uZu"},"source":["vgg = VGG()\n","vgg.eval()\n","img, _ = next(iter(trn_dl))\n","pred = vgg(img).argmax(dim=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SpbbZ-wU4aiN"},"source":["pred[:, 386].backward()\n","gradients = vgg.get_activations_gradient()\n","pooled_gradients = torch.mean(gradients, dim=[0, 2, 3])\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"H7kz4aJ-lnc3"},"source":["from torchsummary import summary\n","model, loss_fn, optimizer = get_model()\n","summary(model, input_size=(3, 224, 224))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TZ746KVElpEn"},"source":["def train_batch(x, y, model, opt, loss_fn):\n","    prediction = model(x)\n","    batch_loss = loss_fn(prediction, y)\n","    batch_loss.backward()\n","    optimizer.step()\n","    optimizer.zero_grad()\n","    return batch_loss.item()\n","\n","@torch.no_grad()\n","def accuracy(x, y, model):\n","    prediction = model(x)\n","    is_correct = (prediction > 0.5) == y\n","    return is_correct.cpu().numpy().tolist()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rP90lBfolrCx"},"source":["def get_data():\n","    train = cats_dogs(train_data_dir, transform=trn_tfms)\n","    trn_dl = DataLoader(train, batch_size=32, shuffle=True, collate_fn=train.collate_fn)\n","    val = cats_dogs(test_data_dir, transform=trn_tfms)\n","    val_dl = DataLoader(val, batch_size=32, shuffle=True, collate_fn=val.collate_fn)\n","    return trn_dl, val_dl"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qH5LvtRHlsu0"},"source":["@torch.no_grad()\n","def val_loss(x, y, model):\n","    prediction = model(x)\n","    val_loss = loss_fn(prediction, y)\n","    return val_loss.item()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"syzRT90slvJh"},"source":["trn_dl, val_dl = get_data()\n","model, loss_fn, optimizer = get_model()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zcNVQowNlwsW"},"source":["train_losses, train_accuracies = [], []\n","val_losses, val_accuracies = [], []\n","for epoch in range(10):\n","    \n","    print(epoch)\n","    train_epoch_losses, train_epoch_accuracies = [], []\n","    val_epoch_accuracies = []\n","    for ix, batch in enumerate(iter(trn_dl)):\n","        #print(ix)\n","        x, y = batch\n","        batch_loss = train_batch(x, y, model, optimizer, loss_fn)\n","        train_epoch_losses.append(batch_loss)        \n","    train_epoch_loss = np.array(train_epoch_losses).mean()\n","\n","    for ix, batch in enumerate(iter(trn_dl)):\n","        x, y = batch\n","        is_correct = accuracy(x, y, model)\n","        train_epoch_accuracies.extend(is_correct)\n","    train_epoch_accuracy = np.mean(train_epoch_accuracies)\n","\n","    for ix, batch in enumerate(iter(val_dl)):\n","        x, y = batch\n","        val_is_correct = accuracy(x, y, model)\n","        val_epoch_accuracies.extend(val_is_correct)\n","        #validation_loss = val_loss(x, y, model)\n","    val_epoch_accuracy = np.mean(val_epoch_accuracies)\n","\n","    train_losses.append(train_epoch_loss)\n","    train_accuracies.append(train_epoch_accuracy)\n","    #val_losses.append(validation_loss)\n","    val_accuracies.append(val_epoch_accuracy)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"i9gw0z46lz2S"},"source":["im2fmap = nn.Sequential(*(list(model.model[:5].children()) + list(model.model[5][:2].childeren())))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hcn1677Kq42Y"},"source":["def im2gradCAM(x):\n","    model.eval()\n","    logits = model(x)\n","    heatmaps = []\n","    activations = im2fmap(x)\n","    print(activations.shape)\n","    pred = logits.max(-1)[-1]\n","    # get the model's prediction\n","    model.zero_grad()\n","    # compute gradients with respect to model's most confident logit\n","    logits[0,pred].backward(retain_graph=True)\n","    # get the gradients at the required featuremap location\n","    # and take the avg gradient for every featuremap\n","    pooled_grads = model.model[-6][1].weight.grad.data.mean((1,2,3))\n","    # multiply each activation map with corresponding gradient average\n","    for i in range(activations.shape[1]):\n","        activations[:,i,:,:] *= pooled_grads[i]\n","    # take the mean of all weighted activation maps\n","    # (that has been weighted by avg. grad at each fmap)\n","    heatmap = torch.mean(activations, dim=1)[0].cpu().detach()\n","    return heatmap, 'Uninfected' if pred.item() else 'Parasitized'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JsJEHUbmrDu5"},"source":["SZ = 224\n","def upsampleHeatmap(map, img):\n","    m,M = map.min(), map.max()\n","    map = 255 * ((map-m) / (M-m))\n","    map = np.uint8(map)\n","    map = cv2.resize(map, (SZ,SZ))\n","    map = cv2.applyColorMap(255-map, cv2.COLORMAP_JET)\n","    map = np.uint8(map)\n","    map = np.uint8(map*0.7 + img*0.3)\n","    return map"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"E9AXScuhx7aZ"},"source":["N = 20\n","_val_dl = DataLoader(val_ds, batch_size=N, shuffle=True, collate_fn=val_ds.collate_fn)\n","x,y,z = next(iter(_val_dl))\n","\n","for i in range(N):\n","    image = resize(z[i], SZ)\n","    heatmap, pred = im2gradCAM(x[i:i+1])\n","    if(pred=='Uninfected'):\n","        continue\n","    heatmap = upsampleHeatmap(heatmap, image)\n","    subplots([image, heatmap], nc=2, figsize=(5,3), suptitle=pred)"],"execution_count":null,"outputs":[]}]}